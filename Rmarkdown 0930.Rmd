---
title: "Preliminary data cleaning and analysis for exploring Schedule instability"
author: "Zhuofei"
date: "`r Sys.Date()`"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Sequence analysis practise
This is Zhuofei Lu's practise of sequence analysis. The original code drawn from
Kamila Kolpashnikova:<https://github.com/Kolpashnikova/Sequence_Analysis_Workshop.git>.

## Install packages

```{r}
if (!require("pacman")) install.packages("pacman")
```

## Loading required package: pacman

```{r}
library(pacman)
```

## load and install packages

```{r}
pacman::p_load(TraMineR, TraMineRextras, cluster, RColorBrewer, devtools, haven, 
               tidyverse, reshape2, WeightedCluster, nnet)
```

## Load .dta (Stata) Dataset

```{r}
setwd("E:/OneDrive/SciencesPo/data")
## LL: you should create a R project using this directory instead of setting manually your working directory
## it makes your code stronger and independent of personal configurations
X3 <- read_dta("3days_cleaned0928.dta")
## I would also suggest not to use capital letters for R objects as it makes the code a little bit more difficult to write
## and if you use only lower cases as a rule, it makes R code safer from case errors
```

## Color Palette

```{r}
colourCount = 13
getPalette = colorRampPalette(brewer.pal(9, "Set3"))
```





############################### [Updated on 11/10/2023] intra-individual measure of schedule instability (using 2 diary days) 

dat <- tibble(id = c(1,1,2,2),
              x1 = c(0,1,1,1),
              x2 = c(0,1,1,1),
              x3 = c(0,1, 0, 1))
# with dplyr

dat %>%
  group_by(id) %>%
  summarise(d = dist(data.frame(x1, x2, x3), method = "manhattan”))

# with data.table

setDT(dat)
dat[ , .(d = dist(.SD, method = "manhattan")), by = id, .SD = x1:x3]


############################### [Updated on 17/10/2023] intra-individual measure of schedule instability (using 3 diary days)
## Example for practise
library(data.table)
library(tibble)

dat <- tibble(id = c(1,1,1,2,2,2),
              x1 = c(0,1,0,0,1,1),
              x2 = c(1,1,0,1,1,1),
              x3 = c(0,1,0,1,0,1))
setDT(dat)

# use data.table to estimate manhattan distance
distances_df <- dat[, .(distance = dist(.SD, method = "manhattan")), by = id, .SDcols = x1:x3]

# print manhattan distance
print(distances_df)

# use data.table  to estimate mean and variance
summary_stats <- distances_df[, .(mean_distance = mean(distance), variance = var(distance)), by = id]

# print mean and variance
print(summary_stats)


############################### [Updated on 23/10/2023] Use UKTUS for practise 
---
title: "Schedule instability"
author: "Zhuofei"
date: "2023-10-23"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Library packages
```{r message=FALSE, include=FALSE}
library(haven)
library(data.table)
library(tibble)
library(tidyverse)
library(TraMineR)
library(cluster)
library(dplyr)
library(ggplot2)
```
## Read data UKTUS 3days cleaned

```{r}
setwd("C:/Zhuofei Lu/OneDrive/SciencesPo/Schedule instability/data")
X3 <- read_dta("3days_cleaned0928.dta")
```

## Keep those who have at least 2 diary days (new subset: d2)
At this stage, we drop (1763-1164=599) cases

```{r}
X3 <- X3 %>%
  group_by(mainid) %>%
  mutate(ndays = n())
d2 <- X3  %>%
  filter(ndays >= 2)
head(d2$mainid)
```

## Calculate the manhattan distance
```{r}
setDT(d2)

distances_df <- d2[, .(distance = dist(.SD, method = "manhattan")), by = mainid, .SDcols = w_pri1:w_pri144]
print(distances_df)

mean_distances <- distances_df[, .(mean_distance = mean(distance)), by = mainid]

d2 <- d2 %>% 
  left_join(mean_distances, by = "mainid")

summary(d2$mean_distance)
```

## Slice the sample, keep only one observation for each respondent
At this stage, we drop (599-568=31) cases

```{r}
d2 <- read_dta("d2.dta")

d3 <- d2 %>%
  group_by(mainid) %>%
  slice_sample(n = 1)
```

```{r}
print(d3)
```

## Drop cases who were not in paid employment
At this stage, we drop (568-567=1) cases

```{r}
d3 <- d3[d3$headocc3 != 4, ]
```

## Predict schedule instability
## Discriptive statistics
```{r pressure, echo=FALSE}
library(ggplot2)
library(dplyr)

d3$headocc3 <- as.factor(as.character(d3$headocc3))
d3$wfh <- factor(d3$wfh, levels = c(1, 2), labels = c("Travel to Work", "Work from Home"))


d3_summary <- d3 %>%
  group_by(headocc3, wfh) %>%
  summarise(mean_distance = mean(mean_distance, na.rm = TRUE))


p <- ggplot(d3_summary, aes(x=headocc3, y=mean_distance, fill=wfh)) + 
  geom_bar(stat="identity", position="dodge") +
  labs(y="Mean of mean_distance", x="Headocc3 Categories") +
  theme_minimal() +
  scale_fill_manual(name="Work Mode", 
                    values = c("Travel to Work" = "grey40", "Work from Home" = "grey80")) +
  scale_x_discrete(labels=c("1"="High", "2"="Intermediate", "3"="Routine"))

print(p)

```
## Regression OLS
```{r}
model1 <- lm(mean_distance ~ factor(wfh)+ factor(headocc3) + factor(sex)+ factor(child)+ factor(health)+ factor(marstat) + age  + labin2
             , data=d3, weight=daywtq)
summary(model1)
```
## Moderating role of class
```{r}
model2 <- lm(mean_distance ~ factor(wfh)*factor(headocc3) + factor(sex)+ factor(child)+ factor(health)+ factor(marstat) + age  + labin2
             , data=d3, weight=daywtq)
summary(model2)
```

## Plot the interaction
```{r}
all_combinations <- expand.grid(
  wfh = unique(d3$wfh),
  headocc3 = unique(d3$headocc3),
  sex = unique(d3$sex),
  child = unique(d3$child),
  health = unique(d3$health),
  marstat = unique(d3$marstat),
  age = median(d3$age, na.rm = TRUE), 
  labin2 = median(d3$labin2, na.rm = TRUE)
)
```

## Predict interaction terms using the model results
```{r}
all_combinations$predicted <- predict(model2, all_combinations)

```

## Plot
```{r}
p1<- ggplot(all_combinations, aes(x=factor(wfh), y=predicted, group=factor(headocc3), color=factor(headocc3))) + 
  geom_line(aes(linetype=factor(headocc3))) + 
  geom_point(aes(shape=factor(headocc3))) + 
  labs(y="Predicted mean_distance", x="WFH", color="Headocc3 Levels", linetype="Headocc3 Levels", shape="Headocc3 Levels") +
  theme_minimal()

print(p1)
```

## Repeat by using Tobit
```{r message=FALSE}
library(AER)
```
```{r}
model_tobit1 <- tobit(mean_distance ~ factor(wfh) + factor(headocc3) + factor(sex) + factor(child) + factor(health) + factor(marstat) + age + labin2, 
                     data = d3, weights = daywtq, left=0) # left=0 表示下限是0

summary(model_tobit1)

```{r}
model_tobit2 <- tobit(mean_distance ~ factor(wfh)*factor(headocc3) + factor(sex) + factor(child) + factor(health) + factor(marstat) + age + labin2, 
                     data = d3, weights = daywtq, left=0) # left=0 表示下限是0

summary(model_tobit2)

```


